# QD-LLM: Quantum Knowledge Distillation for Large Language Models

QD-LLM is a novel framework that distills the power of large language models (LLMs) into compact quantum student models using variational quantum circuits. This enables efficient deployment of NLP models on resource-constrained hardware while maintaining high performance.



ğŸ“„ Paper: Quantum Knowledge Distillation for Large Language Models

ğŸ§‘â€ğŸ’» Authors: Lingxiao Li*, Yihao Wang*, Jiacheng Fan, Jing Li, Sujuan Qin, Qiaoyan Wen, Fei Gao

ğŸ« Affiliations: Beijing University of Posts and Telecommunications


ğŸš€ Highlights:

ğŸ” Distills LLMs like LLaMA2/3, OPT, BLOOMZ into quantum circuits

ğŸŒŒ Achieves comparable or better performance than TinyBERT, DistilBERT, MiniLLM, etc.

âš¡ Only 9K parameters in the quantum model (~0.02% of classical distillation baselines)

ğŸ’» Classical simulation + ğŸ§ª Deployment on real quantum hardware (Quafu superconducting processor)

ğŸ§  Quantum-Inspired Classical Algorithm: even classical simulations show strong compression + accuracy 


ğŸ§ª Benchmark Tasks
QD-LLM is evaluated on:
| Task              | Dataset Size | Classes | Avg. Text Length |
| ----------------- | ------------ | ------- | ---------------- |
| Emotion Analysis  | 24,000       | 2       | 33.17            |
| Hiding Detection  | 10,000       | 2       | 10.80            |
| Thematic Analysis | 20,000       | 4       | 13.96            |


These datasets can be seen in the Dataset file.

ğŸŒ Open-Source LLMs Used

| Model    | Links                                                             |
| ---------| ----------------------------------------------------------------- |
| LLaMA 2  | Meta AI (https://github.com/meta-llama/llama)                     |
| LLaMA 3  | Meta AI (https://ai.meta.com/llama/)                              |
| OPT      | OPT GitHub (https://github.com/facebookresearch/metaseq)          |
| BLOOMZ   | BLOOMZ on HuggingFace (https://huggingface.co/bigscience/bloomz)  |



ğŸ§Š Real-device 
The details of the deployment are shown in real_device_baihua. We thank the Quafu Quantum Cloud Platform and the Beijing Institute of Technology for their support during the real-device evaluation.

ğŸ“¬ Contact
For questions or collaborations:

Lingxiao Li: lingxiao_li@bupt.edu.cn




